{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "# Nous vérifions si le fichier existe ou non avant de le supprimer.\n",
    "if os.path.exists('C:/Users/carla/Desktop/telechargements/data.zip'):\n",
    "    os.remove('C:/Users/carla/Desktop/telechargements/data.zip')\n",
    "else:\n",
    "    print(\"Impossible de supprimer le fichier car il n'existe pas\")\n",
    "# Nous effaçons le dossier et tous les fichiers\n",
    "try :\n",
    "  shutil.rmtree(\"C:/Users/carla/Desktop/dezipage/data_unzipped\", ignore_errors=True)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "\n",
    "# Téléchargement du fichier dans le dossier \"telechargements\"\n",
    "url =\"https://diffuseur.datatourisme.gouv.fr/webservice/024d893f2af1b82ab4ca5d66dec6df0c/cd13e69e-874b-4eaf-ac53-8f5c8680fec0\"\n",
    "r = requests.get(url, r'C:/Users/carla/Desktop/telechargements/data.zip')\n",
    "with open(r'C:/Users/carla/Desktop/telechargements/data.zip', 'wb') as f:\n",
    "    f.write(r.content)\n",
    "    \n",
    "# dezipage des fichiers dans le dossier \"dezipage\"\n",
    "with ZipFile(r'C:/Users/carla/Desktop/telechargements/data.zip') as zipObj:\n",
    "    zipObj.extractall(path='C:/Users/carla/Desktop/dezipage/data_unzipped', members=None, pwd=None)\n",
    "\n",
    "     \n",
    "# Chemin d'accès du fichier INDEX qui regroupe tous les POI\n",
    "index_json_file_path = 'C:/Users/carla/Desktop/dezipage/data_unzipped/index.json'\n",
    "\n",
    "# Overture et lecture du fichier INDEX\n",
    "with open(index_json_file_path, 'r', encoding='utf8', errors='ignore') as j:\n",
    "     contents = json.loads(j.read())\n",
    "        \n",
    "\n",
    "# Création de la liste de tous les chemins d'accès de tous les fichiers JSON\n",
    "json_files_path = []\n",
    "\n",
    "# Boucle pour avoir tous les chemins d'accès de tous les fichiers JSON\n",
    "for i in range(len(contents)):\n",
    "    json_file_subdirectory = contents[i]['file']\n",
    "    complete_json_file_directory = 'C:/Users/carla/Desktop/dezipage/data_unzipped/objects/' + json_file_subdirectory\n",
    "    json_files_path.append(complete_json_file_directory)\n",
    "\n",
    "\n",
    "# Création des listes\n",
    "#labels = []\n",
    "tags_list = []\n",
    "cities = []\n",
    "#postal_codes = []\n",
    "#codes_insee =[]\n",
    "lats=[]\n",
    "longs=[]\n",
    "#departements=[]\n",
    "regions=[]\n",
    "code_regions=[]\n",
    "office_tourismes=[]\n",
    "fournisseurs=[]\n",
    "ids_poi=[]\n",
    "photos=[]\n",
    "\n",
    "\n",
    "# Boucle pour récupérer toutes les informations qu'on souhaite dans les fichiers JSON\n",
    "for json_file_path in json_files_path:\n",
    "    \n",
    "        with open(json_file_path, 'r',encoding='utf8', errors='ignore') as j:\n",
    "            contents = json.loads(j.read())\n",
    "    \n",
    "        #try:\n",
    "            #label = contents['rdfs:label']['fr'][0]\n",
    "            #labels.append(label)\n",
    "        #except:\n",
    "            #labels.append('NaN')\n",
    "\n",
    "        try:\n",
    "            tags = contents['@type']\n",
    "            tags_list.append(tags)\n",
    "        except:\n",
    "            tags_list.append('NaN')\n",
    "\n",
    "        try:\n",
    "            city = contents['isLocatedAt'][0]['schema:address'][0]['schema:addressLocality']\n",
    "            cities.append(city)\n",
    "        except:\n",
    "            cities.append('NaN')\n",
    "\n",
    "        #try:\n",
    "           # postal_code = contents['isLocatedAt'][0]['schema:address'][0]['schema:postalCode']\n",
    "           # postal_codes.append(postal_code)\n",
    "       # except:\n",
    "          #  postal_codes.append('NaN')\n",
    "        #    \n",
    "        #try:\n",
    "           ## code_insee= contents['isLocatedAt'][0]['schema:address'][0]['hasAddressCity']['insee']\n",
    "           # codes_insee.append(code_insee)\n",
    "       # except:\n",
    "           # codes_insee.append('NaN')\n",
    "            \n",
    "        try:\n",
    "            lat= contents['isLocatedAt'][0]['schema:geo']['schema:latitude']\n",
    "            lats.append(lat)\n",
    "        except:\n",
    "            lats.append('NaN')\n",
    "            \n",
    "        try:\n",
    "            long= contents['isLocatedAt'][0]['schema:geo']['schema:longitude']\n",
    "            longs.append(long)\n",
    "        except:\n",
    "            longs.append('NaN')\n",
    "        \n",
    "        #    \n",
    "        #try:\n",
    "            #departement = contents['isLocatedAt'][0]['schema:address'][0]['hasAddressCity']['isPartOfDepartment']['rdfs:label']['fr']\n",
    "            #departements.append(departement)\n",
    "        \n",
    "       # except:\n",
    "           # departements.append('NaN')\n",
    "            \n",
    "        try:\n",
    "            region = contents['isLocatedAt'][0]['schema:address'][0]['hasAddressCity']['isPartOfDepartment']['isPartOfRegion']['rdfs:label']['fr']\n",
    "            regions.append(region)\n",
    "        except:\n",
    "            regions.append('NaN')\n",
    "        \n",
    "        try:\n",
    "            code_region = contents['isLocatedAt'][0]['schema:address'][0]['hasAddressCity']['isPartOfDepartment']['insee']\n",
    "            code_regions.append(code_region)\n",
    "        except:\n",
    "            code_regions.append('NaN')\n",
    "        \n",
    "        try:\n",
    "            office_tourisme= contents['hasBeenCreatedBy']['schema:legalName']\n",
    "            office_tourismes.append(office_tourisme)\n",
    "        except:\n",
    "            office_tourismes.append('NaN')\n",
    "            \n",
    "        try:\n",
    "            fournisseur= contents['hasBeenPublishedBy'][0]['schema:legalName']\n",
    "            fournisseurs.append(fournisseur)\n",
    "        except: \n",
    "            fournisseurs.append('NaN')\n",
    "            \n",
    "        try:\n",
    "            id_poi=contents['@id']\n",
    "            ids_poi.append(id_poi)\n",
    "        except:\n",
    "            ids_poi.append('NaN')\n",
    "        \n",
    "        try:\n",
    "            photo= contents['hasMainRepresentation'][0]['ebucore:hasRelatedResource'][0]['ebucore:locator']\n",
    "            photos.append(photo)\n",
    "        except: \n",
    "            photos.append('NaN')\n",
    "        \n",
    "            \n",
    "# Création du dataframe df \n",
    "df = pd.DataFrame({#'poi': labels,\n",
    "    'ville': cities,\n",
    "    #'code_postale': postal_codes,\n",
    "    #'code_insee': codes_insee,\n",
    "    'region': regions,\n",
    "    'code_departement':code_regions,\n",
    "   # 'departement': departements,\n",
    "    'latitude': lats,\n",
    "    'longitude': longs,\n",
    "    'createur_donnée': office_tourismes,\n",
    "    'fournisseur': fournisseurs,\n",
    "    'id_poi':ids_poi,\n",
    "    'photo': photos,\n",
    "    'tag': tags_list                                \n",
    "})\n",
    "\n",
    "df\n",
    "\n",
    "# Nettoyage des colonnes \n",
    "#df['departement']=df['departement'].apply(str).str.replace(\"[\",\"\").apply(str).str.replace(\"]\",\"\").apply(str).str.replace(\"'\",\"\")\n",
    "df['region']=df['region'].apply(str).str.replace(\"[\",\"\").apply(str).str.replace(\"]\",\"\").apply(str).str.replace(\"'\",\"\")\n",
    "df['photo']=df['photo'].str.replace(\"[\",\"\").str.replace(\"]\",\"\").str.replace(\"'\",\"\")\n",
    "df['tag']=df['tag'].apply(str).str.replace(\"[\",\"\").apply(str).str.replace(\"]\",\"\").apply(str).str.replace(\"'\",\"\")\n",
    "\n",
    "\n",
    "# Creation des catégories mères\n",
    "df[\"categorie_mere\"] = ((df[\"tag\"].apply(lambda x: 'PlaceOfInterest' if 'PlaceOfInterest' in x else 'Product' if 'Product' in x else 'EntertainmentAndEvent' if 'EntertainmentAndEvent' in x else 'Tour')))\n",
    "\n",
    "\n",
    "# Mettre la colonne 'photo' en booléen\n",
    "df.photo[df.photo.notna()] = True\n",
    "df.photo[df.photo.isna()] = False\n",
    "df['photo']=df['photo'].astype(bool)\n",
    "\n",
    "\n",
    "#Trouver dans la colonne 'tag' tous les 'schema:...' pour les effacer\n",
    "df1= df['tag'].str.split(',',expand = True).stack().explode().value_counts().reset_index()\n",
    "df1=df1.rename(columns={'index': 'cat'})\n",
    "#df1\n",
    "\n",
    "#trouver tous les 'schema:'\n",
    "z=pd.DataFrame([(df1.cat.str.split(',',expand = True).stack().explode()),(df1.cat.str.split(',',expand = True).stack().explode().str.contains(\"schema\").astype(str))]).transpose()\n",
    "\n",
    "w=z[z.iloc[:,1] == 'True']\n",
    "\n",
    "# La liste des \"schema\"\n",
    "w=list(w[0])\n",
    "\n",
    "df['tag2']=df['tag']\n",
    "\n",
    "for i in w:\n",
    "    df.tag2= df.tag2.str.replace(i+', ','')\n",
    "    df.tag2= df.tag2.str.replace(i,'')\n",
    "    \n",
    "    \n",
    "df.drop(['tag'], axis='columns', inplace= True)\n",
    "df=df.rename(columns={'tag2': 'tag'})\n",
    "\n",
    "\n",
    "# Fonction pour trouver les sous_catégories dans la colonne 'categorie_mere'\n",
    "def categorie_tag(x):\n",
    "    a= []\n",
    "    # Création de la liste avec toutes les sous catégories\n",
    "    liste_u= [\"CyclingTour\",\"FluvialOrSeaTour\",\"RoadTour\",\"UnderwaterTour\",\"WalkingTour\",\"HorseTour\",\"Accommodation\",\"BusinessPlace\",\"MedicalPlace\",\"NaturalHeritage\",\"CulturalSite\",\"FoodEstablishment\",\"TastingProvider\",\"ActivityProvider\",\"TouristInformationCenter\",\"Transport\",\"ConvenientService\",\"ServiceProvider\",\"SportsAndLeisurePlace\",\"Store\",\"BusinessEvent\",\"CulturalEvent\",\"SaleEvent\",\"SocialEvent\",\"SportsAndRecreationEvent\"]\n",
    "    for i in liste_u:\n",
    "    \n",
    "        if i in x:\n",
    "            \n",
    "            a.append(i)\n",
    "    return a\n",
    "\n",
    "\n",
    "# Application de la fonction\n",
    "df[\"sous_categorie\"] = df[\"tag\"].apply(categorie_tag)\n",
    "\n",
    "\n",
    "# Nettoyage de la colonne 'sous_categorie'\n",
    "df[\"sous_categorie\"]=df[\"sous_categorie\"].astype(str).str.replace(\"[\",\"\").astype(str).str.replace(\"]\",\"\").astype(str).str.replace(\"'\",\"\")\n",
    "\n",
    "# Création du dataframe df_erreur_tag\n",
    "df_erreur_tag=df[(df['categorie_mere']== 'Lieu') & (df.tag.str.contains('Event'))]\n",
    "\n",
    "# Nettoyage des colonnes latitude et longitude\n",
    "df['latitude']=df['latitude'].astype(float)\n",
    "df['longitude']=df['longitude'].astype(float)\n",
    "df['latitude']=df['latitude'].round(6)\n",
    "df['longitude']=df['longitude'].round(6)\n",
    "\n",
    "# Création du dataframe df_erreur_lat_lon\n",
    "df_erreur_lat_lon = (df[(df.latitude.round(4) > 52)|(df.latitude.round(4) < 41)|(df.longitude.round(4) >10)|(df.longitude.round(4) <-6)])\n",
    "df_erreur_lat_lon['len_dpt'] = df_erreur_lat_lon.code_departement.astype(str).apply(len)\n",
    "df_erreur_lat_lon = df_erreur_lat_lon[df_erreur_lat_lon.len_dpt == 2]\n",
    "df_erreur_lat_lon = df_erreur_lat_lon.iloc[:,0:-1]\n",
    "    \n",
    "\n",
    "# Retirer la colonne 'tag' pour alléger encore plus le dataframe\n",
    "df.drop(['tag'], axis='columns', inplace= True)\n",
    "\n",
    "\n",
    "def dept_clean(x):\n",
    "    x = str(x)\n",
    "    x = x.replace(\".0\",\"\")\n",
    "    if len(x) == 1:\n",
    "        x = \"0\"+ x\n",
    "    return x\n",
    "df['code_departement'] = df.code_departement.apply(dept_clean)\n",
    "\n",
    "\n",
    "# Traduction en français\n",
    "#categorie_mere\n",
    "df['categorie_mere']=df['categorie_mere'].str.replace(\"PlaceOfInterest\",\"Lieu\")\n",
    "df['categorie_mere']=df['categorie_mere'].str.replace('Product','Produit')\n",
    "df['categorie_mere']=df['categorie_mere'].str.replace('Tour','Itinéraire Touristique')\n",
    "df['categorie_mere']=df['categorie_mere'].str.replace('EntertainmentAndEvent','Fête et Manifestation')\n",
    "\n",
    "#sous_categorie\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace(\"BusinessEvent\",\"Evenement Professionnel d'Entreprise\")\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('Accommodation','Hébergement')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('BusinessPlace',\"Site d'Affaires\")\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('BusinessLieu',\"Site d'Affaires\")\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('MedicalPlace','Lieu de Santé')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('MedicalLieu','Lieu de Santé')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('NaturalHeritage','Site Naturel')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('CulturalEvent','Evènement Culturel')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('CulturalSite','Site Culturel')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('FoodEstablishment','Restauration')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('EntertainmentAndEvent','Fête et manifestation')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('CyclingTour','Itinéraire cyclable')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('TastingProvider','Fournisseur de dégustation')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('FluvialOrSeaTour','Itinéraire fluvial ou maritime')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('RoadTour','Itinéraire routier')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('ActivityProvider',\"Prestataire d'activité\")\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('UnderwaterTour','Itinéraire sous-marin')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('TouristInformationCenter',\"Service d'information Touristique\")\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('Transport','Transport')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('ConvenientService','Prestataire de Service')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('WalkingTour','Itinéraire Pédestre')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('HorseTour','Itinéraire Equestre')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('SaleEvent','Evènement Commercial')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('SocialEvent','Evènement Social')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('SportsAndRecreationEvent','Evènement Sports et Loisirs')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('ServiceProvider','Prestataire de service')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('SportsAndLeisurePlace','Site Sportif, Récréatif et de Loisirs')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('SportsAndLeisureLieu','Site Sportif, Récréatif et de Loisirs')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('Store','Commerce de détail')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('Place','Lieu')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('Product','Produit')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('Visit','Visite')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('Visitee','Visite')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('Practice','Pratique')\n",
    "df['sous_categorie']=df['sous_categorie'].str.replace('Rental','Location')\n",
    "\n",
    "#Factorisation des villes\n",
    "df['ville']=df['ville'].factorize()[0]\n",
    "\n",
    "#Separation des dataframes en categorie_mere\n",
    "df_lieu=df[df['categorie_mere']== 'Lieu']\n",
    "df_produit=df[df['categorie_mere']== 'Produit']\n",
    "df_it=df[df['categorie_mere']== 'Itinéraire Touristique']\n",
    "df_fete=df[df['categorie_mere']== 'Fête et Manifestation']\n",
    "\n",
    "# Charger les dataframe en CSV avec séparateur \n",
    "df.to_csv('df_tourisme.zip',sep=' ',index=False)\n",
    "df_lieu.to_csv('df_lieu.zip',sep=' ',index=False)\n",
    "df_produit.to_csv('df_produit.zip',sep=' ',index=False)\n",
    "df_it.to_csv('df_it.zip',sep=' ',index=False)\n",
    "df_fete.to_csv('df_fete.zip',sep=' ',index=False)\n",
    "df_erreur_tag.to_csv('df_erreur_tag.csv',sep=' ',index=False)\n",
    "df_erreur_lat_lon.to_csv('df_erreur_lat_lon.csv',sep=' ',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
